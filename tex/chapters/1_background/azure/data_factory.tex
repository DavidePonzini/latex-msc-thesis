Azure Data Factory can be defines as a cloud-based data integration service that allows users to create data-driven workflows in the cloud for orchestrating and automating data movement and data transformation \cite{bib:azure:datafactory:intro}.

Users can create workflows that ingest data from different sources.
These workflows can apply operation of the data using different cloud services, such as Hadoop or Spark.
The results can be published to cloud data stores, such as Azure SQL Data Warehouse or Azure Data Lake.

\paragraph{Advantages and Limitations}
    This service is very effective for performing basic operations, such as reading from a data source and writing on a different one.
    Basic transformation operations can also be applied.
    
    These simple workflows can be developed in just a few minutes using the graphical interface.
    
    However, this tool isn't suited for more complex operations, since it isn't possible to write code directly, but it is necessary to use the user interface.
    In these cases, coding in Databricks proves to be easier and more versatile.